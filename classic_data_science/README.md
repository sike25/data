# Data-Science

### Project One: Countries, Sports and Income
Investigating income inequality and life expectancy indicators for different countries and region using data from the [gapminder website](https://www.gapminder.org/data/)
And some exploratory data analysis (EDA) on [this Kaggle data repository](https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results?select=athlete_events.csv) which holds 120 years of Olympic history.

### Project Two: APIs, Web Scraping and Decision Trees
Ran EDA on news headlines retrieved from the [New York Times Archive API](https://www.gapminder.org/data/](https://developer.nytimes.com/docs/archive-product/1/overview)https://developer.nytimes.com/docs/archive-product/1/overview). Scraped and filtered information about university rankings from the [Round University Ranking](https://www.gapminder.org/data/) website, and built a wordcloud. Improved on a kNN classification problem on a with a decision tree (predicting bank customers as PEPs or not), and analyzed splitting attribute importance.

### Project Three: Cross Validation and CRISP-DM
Using the [UCI Wine Quality Database](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv), we use ten-fold cross validation and the F1 score to assess hyperparamters for kNN and decision tress classifiers (number of neighbours, maximum depth). Then we write a 500 word essay on designing a CRISP-DM analysis for predicting the drop out rates for college freshmen. We explain its validaity as a data science problem, and possible ethical considerations with the project.

### Project Four: Polynomial Regression and Neural Networks
Simulating data from some known probability distribution, to investigate how the degree of a polynomial regression and the size of the training set affects its performance (measured in root mean squared error). Then building a neural network to solve the [MNIST Image Dataset](https://keras.io/api/datasets/mnist/) and evaluating that model on some of my own handwritten digits.

### Project Five: K-Means Clustering, Pair plots and PCA  
Performing K-Means clustering on [Airbnb NYC listings](https://insideairbnb.com/get-the-data/) to group similar accommodations. We preprocessed the data by handling missing values, normalizing numerical features, and encoding categorical features. The optimal number of clusters (k=4) was determined using the Elbow Method and evaluated with the Silhouette Score. We visualized the clusters using both pair plots and PCA, ensuring a comprehensive understanding of the data structure and cluster distribution.

